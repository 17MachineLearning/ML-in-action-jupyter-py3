{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 基于数据集多重抽样的分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.1 bagging：基于数据随机重抽样的分类器构建方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.2 boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 训练算法：基于错误提升分类器的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\varepsilon=\\frac{\\text{未正确分类的样本数目}}{\\text{所有样本数目}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\alpha=\\frac12\\ln\\left(\\frac{1-\\varepsilon}{\\varepsilon}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$D_i^{(t+1)} = \\frac{D_i^{(t)}\\mathrm{e}^{-\\alpha}}{\\text{Sum}(D)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$D_i^{(t+1)} = \\frac{D_i^{(t)}\\mathrm{e}^{\\alpha}}{\\text{Sum}(D)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3 基于单层决策树构建弱分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_simp_data():\n",
    "    dat_mat = matrix([[1., 2.1],\n",
    "                     [2., 1.1],\n",
    "                     [1.3, 1.],\n",
    "                     [1., 1.],\n",
    "                     [2., 1.]])\n",
    "    class_labels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return dat_mat, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_mat, class_labels = load_simp_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**程序清单7-1** 单层决策树生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stump_classify(data_matrix, dimen, thresh_val, thresh_ineq):\n",
    "    ret_array = ones((shape(data_matrix)[0], 1))\n",
    "    if thresh_ineq == 'lt':\n",
    "        ret_array[data_matrix[:,dimen] <= thresh_val] = -1.0\n",
    "    else:\n",
    "        ret_array[data_matrix[:,dimen] > thresh_val] = -1.0\n",
    "    return ret_array\n",
    "\n",
    "def build_stump(data_arr, class_labels, D):\n",
    "    data_matrix = mat(data_arr)\n",
    "    label_mat = mat(class_labels).T\n",
    "    m,n = shape(data_matrix)\n",
    "    num_steps = 10.0\n",
    "    best_stump = {}\n",
    "    best_clas_est = mat(zeros((m,1)))\n",
    "    min_error = inf\n",
    "    for i in range(n):\n",
    "        range_min = data_matrix[:,i].min()\n",
    "        range_max = data_matrix[:,i].max()\n",
    "        step_size = (range_max-range_min)/num_steps\n",
    "        for j in range(-1, int(num_steps)+1):\n",
    "            for inequal in ['lt', 'gt']:\n",
    "                thresh_val = (range_min + float(j)*step_size)\n",
    "                predicted_vals = \\\n",
    "                stump_classify(data_matrix, i, thresh_val, inequal)\n",
    "                err_arr = mat(ones((m,1)))\n",
    "                err_arr[predicted_vals == label_mat] = 0\n",
    "                weighted_error = D.T * err_arr\n",
    "                '''\n",
    "                print('split: dim {}, thresh {}, thresh inequal: \\\n",
    "                {}, the weighted error is {}'\\\n",
    "                     .format(i, thresh_val, inequal, weighted_error))\n",
    "                '''\n",
    "                if weighted_error < min_error:\n",
    "                    min_error = weighted_error\n",
    "                    best_clas_est = predicted_vals.copy()\n",
    "                    best_stump['dim'] = i\n",
    "                    best_stump['thresh'] = thresh_val\n",
    "                    best_stump['ineq'] = inequal\n",
    "    return best_stump, min_error, best_clas_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = mat(ones((5,1))/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.2],\n",
       "        [ 0.2],\n",
       "        [ 0.2],\n",
       "        [ 0.2],\n",
       "        [ 0.2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'ineq': 'lt', 'thresh': 1.3}, matrix([[ 0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_stump(dat_mat, class_labels, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4 完整AdaBoost算法的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**程序清单7-2** 基于单层决策树的AdaBoost训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ada_boost_train_DS(data_arr, class_labels, num_it = 40):\n",
    "    weak_class_arr = []\n",
    "    m = shape(data_arr)[0]\n",
    "    D = mat(ones((m,1))/m)\n",
    "    agg_class_est = mat(zeros((m,1)))\n",
    "    for i in range(num_it):\n",
    "        best_stump, error, class_est = build_stump(data_arr, class_labels, D)\n",
    "        print('D:', D.T)\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))\n",
    "        best_stump['alpha'] = alpha\n",
    "        weak_class_arr.append(best_stump)\n",
    "        print('class_est:', class_est.T)\n",
    "        expon = multiply(-1*alpha*mat(class_labels).T, class_est)\n",
    "        D = multiply(D, exp(expon))\n",
    "        D = D/D.sum()\n",
    "        agg_class_est += alpha * class_est\n",
    "        print('agg_class_est:', agg_class_est.T)\n",
    "        agg_errors = multiply(sign(agg_class_est)!=mat(class_labels).T, ones((m,1)))\n",
    "        error_rate = agg_errors.sum()/m\n",
    "        print('total error:', error_rate, '\\n')\n",
    "        if error_rate == 0.0:\n",
    "            break\n",
    "    return weak_class_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [[ 0.2  0.2  0.2  0.2  0.2]]\n",
      "class_est: [[-1.  1. -1. -1.  1.]]\n",
      "agg_class_est: [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error: 0.2 \n",
      "\n",
      "D: [[ 0.5    0.125  0.125  0.125  0.125]]\n",
      "class_est: [[ 1.  1. -1. -1. -1.]]\n",
      "agg_class_est: [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error: 0.2 \n",
      "\n",
      "D: [[ 0.28571429  0.07142857  0.07142857  0.07142857  0.5       ]]\n",
      "class_est: [[ 1.  1.  1.  1.  1.]]\n",
      "agg_class_est: [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error: 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_array = ada_boost_train_DS(dat_mat, class_labels, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alpha': 0.6931471805599453, 'dim': 0, 'ineq': 'lt', 'thresh': 1.3},\n",
       " {'alpha': 0.9729550745276565, 'dim': 1, 'ineq': 'lt', 'thresh': 1.0},\n",
       " {'alpha': 0.8958797346140273,\n",
       "  'dim': 0,\n",
       "  'ineq': 'lt',\n",
       "  'thresh': 0.90000000000000002}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5 测试算法：基于AdaBoost的分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**程序清单7-3** AdaBoost分类函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ada_classify(dat_to_class, classifier_arr):\n",
    "    data_matrix = mat(dat_to_class)\n",
    "    m = shape(data_matrix)[0]\n",
    "    agg_class_est = mat(zeros((m,1)))\n",
    "    for i in range(len(classifier_arr)):\n",
    "        class_est = stump_classify(data_matrix,\n",
    "                                  classifier_arr[i]['dim'],\n",
    "                                  classifier_arr[i]['thresh'],\n",
    "                                  classifier_arr[i]['ineq'])\n",
    "        agg_class_est += classifier_arr[i]['alpha'] * class_est\n",
    "        print(agg_class_est)\n",
    "    return sign(agg_class_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_arr, label_arr = load_simp_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [[ 0.2  0.2  0.2  0.2  0.2]]\n",
      "class_est: [[-1.  1. -1. -1.  1.]]\n",
      "agg_class_est: [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error: 0.2 \n",
      "\n",
      "D: [[ 0.5    0.125  0.125  0.125  0.125]]\n",
      "class_est: [[ 1.  1. -1. -1. -1.]]\n",
      "agg_class_est: [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error: 0.2 \n",
      "\n",
      "D: [[ 0.28571429  0.07142857  0.07142857  0.07142857  0.5       ]]\n",
      "class_est: [[ 1.  1.  1.  1.  1.]]\n",
      "agg_class_est: [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error: 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_arr = ada_boost_train_DS(dat_arr, label_arr, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69314718]]\n",
      "[[-1.66610226]]\n",
      "[[-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[-1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_classify([0, 0], classifier_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69314718]\n",
      " [-0.69314718]]\n",
      "[[ 1.66610226]\n",
      " [-1.66610226]]\n",
      "[[ 2.56198199]\n",
      " [-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.],\n",
       "        [-1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_classify([[5,5],[0,0]], classifier_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6 示例：在一个难数据集上应用AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**程序清单7-4** 自适应数据加载函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_set(file_name):\n",
    "    num_feat = len(open(file_name).readline().split('\\t'))\n",
    "    data_mat = []\n",
    "    label_mat = []\n",
    "    fr = open(file_name)\n",
    "    for line in fr.readlines():\n",
    "        line_arr = []\n",
    "        cur_line = line.strip().split('\\t')\n",
    "        for i in range(num_feat - 1):\n",
    "            line_arr.append(float(cur_line[i]))\n",
    "        data_mat.append(line_arr)\n",
    "        label_mat.append(float(cur_line[-1]))\n",
    "    return data_mat, label_mat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ada_boost_train_DS(data_arr, class_labels, num_it = 40):\n",
    "    weak_class_arr = []\n",
    "    m = shape(data_arr)[0]\n",
    "    D = mat(ones((m,1))/m)\n",
    "    agg_class_est = mat(zeros((m,1)))\n",
    "    for i in range(num_it):\n",
    "        best_stump, error, class_est = build_stump(data_arr, class_labels, D)\n",
    "        # print('D:', D.T)\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))\n",
    "        best_stump['alpha'] = alpha\n",
    "        weak_class_arr.append(best_stump)\n",
    "        # print('class_est:', class_est.T)\n",
    "        expon = multiply(-1*alpha*mat(class_labels).T, class_est)\n",
    "        D = multiply(D, exp(expon))\n",
    "        D = D/D.sum()\n",
    "        agg_class_est += alpha * class_est\n",
    "        # print('agg_class_est:', agg_class_est.T)\n",
    "        agg_errors = multiply(sign(agg_class_est)!=mat(class_labels).T, ones((m,1)))\n",
    "        error_rate = agg_errors.sum()/m\n",
    "        print('total error:', error_rate)\n",
    "        if error_rate == 0.0:\n",
    "            break\n",
    "    return weak_class_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_arr, label_arr = load_data_set('horseColicTraining2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 0.284280936455\n",
      "total error: 0.284280936455\n",
      "total error: 0.247491638796\n",
      "total error: 0.247491638796\n",
      "total error: 0.254180602007\n",
      "total error: 0.240802675585\n",
      "total error: 0.240802675585\n",
      "total error: 0.220735785953\n",
      "total error: 0.247491638796\n",
      "total error: 0.230769230769\n"
     ]
    }
   ],
   "source": [
    "classifier_array = ada_boost_train_DS(dat_arr, label_arr, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_arr, test_label_arr = load_data_set('horseColicTest2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [-0.46166238]\n",
      " [-0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [-0.46166238]\n",
      " [-0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [-0.46166238]\n",
      " [-0.46166238]\n",
      " [-0.46166238]\n",
      " [-0.46166238]\n",
      " [ 0.46166238]\n",
      " [-0.46166238]\n",
      " [-0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [-0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [-0.46166238]\n",
      " [ 0.46166238]\n",
      " [-0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [-0.46166238]\n",
      " [ 0.46166238]\n",
      " [-0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [-0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]\n",
      " [ 0.46166238]]\n",
      "[[ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [-0.14917993]\n",
      " [-0.14917993]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.14917993]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.14917993]\n",
      " [ 0.14917993]\n",
      " [-0.14917993]\n",
      " [-0.14917993]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [-0.14917993]\n",
      " [-0.14917993]\n",
      " [-0.77414483]\n",
      " [-0.14917993]\n",
      " [ 0.77414483]\n",
      " [-0.14917993]\n",
      " [-0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.14917993]\n",
      " [-0.14917993]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.14917993]\n",
      " [ 0.14917993]\n",
      " [ 0.77414483]\n",
      " [-0.14917993]\n",
      " [ 0.77414483]\n",
      " [-0.14917993]\n",
      " [ 0.14917993]\n",
      " [ 0.14917993]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.14917993]\n",
      " [-0.14917993]\n",
      " [ 0.77414483]\n",
      " [-0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.14917993]\n",
      " [-0.14917993]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]\n",
      " [ 0.77414483]]\n",
      "[[ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [ 0.1376298 ]\n",
      " [-0.43598966]\n",
      " [ 1.06095456]\n",
      " [ 0.4873351 ]\n",
      " [-0.1376298 ]\n",
      " [ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [-0.1376298 ]\n",
      " [-0.1376298 ]\n",
      " [-0.43598966]\n",
      " [-0.43598966]\n",
      " [ 0.4873351 ]\n",
      " [ 0.4873351 ]\n",
      " [ 0.4873351 ]\n",
      " [ 1.06095456]\n",
      " [-0.43598966]\n",
      " [-0.43598966]\n",
      " [-1.06095456]\n",
      " [-0.43598966]\n",
      " [ 1.06095456]\n",
      " [-0.43598966]\n",
      " [-1.06095456]\n",
      " [ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [ 0.4873351 ]\n",
      " [ 1.06095456]\n",
      " [ 0.4873351 ]\n",
      " [ 1.06095456]\n",
      " [-0.1376298 ]\n",
      " [-0.43598966]\n",
      " [ 0.4873351 ]\n",
      " [ 0.4873351 ]\n",
      " [ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [ 0.4873351 ]\n",
      " [ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [-0.1376298 ]\n",
      " [-0.1376298 ]\n",
      " [ 0.4873351 ]\n",
      " [-0.43598966]\n",
      " [ 1.06095456]\n",
      " [ 0.1376298 ]\n",
      " [-0.1376298 ]\n",
      " [-0.1376298 ]\n",
      " [ 0.4873351 ]\n",
      " [ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [ 1.06095456]\n",
      " [ 0.43598966]\n",
      " [ 0.1376298 ]\n",
      " [ 0.4873351 ]\n",
      " [-1.06095456]\n",
      " [ 1.06095456]\n",
      " [-0.1376298 ]\n",
      " [-0.43598966]\n",
      " [ 1.06095456]\n",
      " [ 0.4873351 ]\n",
      " [ 1.06095456]\n",
      " [ 0.4873351 ]]\n",
      "[[ 0.82798452]\n",
      " [ 0.82798452]\n",
      " [ 0.37059985]\n",
      " [-0.66895971]\n",
      " [ 0.82798452]\n",
      " [ 0.72030514]\n",
      " [-0.37059985]\n",
      " [ 0.82798452]\n",
      " [ 0.82798452]\n",
      " [-0.37059985]\n",
      " [-0.37059985]\n",
      " [-0.20301961]\n",
      " [-0.66895971]\n",
      " [ 0.25436505]\n",
      " [ 0.25436505]\n",
      " [ 0.25436505]\n",
      " [ 0.82798452]\n",
      " [-0.66895971]\n",
      " [-0.66895971]\n",
      " [-0.82798452]\n",
      " [-0.66895971]\n",
      " [ 0.82798452]\n",
      " [-0.66895971]\n",
      " [-1.29392461]\n",
      " [ 1.29392461]\n",
      " [ 0.82798452]\n",
      " [ 1.29392461]\n",
      " [ 0.25436505]\n",
      " [ 0.82798452]\n",
      " [ 0.25436505]\n",
      " [ 0.82798452]\n",
      " [-0.37059985]\n",
      " [-0.66895971]\n",
      " [ 0.25436505]\n",
      " [ 0.25436505]\n",
      " [ 0.82798452]\n",
      " [ 0.82798452]\n",
      " [ 0.82798452]\n",
      " [ 0.82798452]\n",
      " [ 0.72030514]\n",
      " [ 0.82798452]\n",
      " [ 0.82798452]\n",
      " [ 0.82798452]\n",
      " [-0.37059985]\n",
      " [-0.37059985]\n",
      " [ 0.25436505]\n",
      " [-0.66895971]\n",
      " [ 0.82798452]\n",
      " [ 0.37059985]\n",
      " [ 0.09534024]\n",
      " [-0.37059985]\n",
      " [ 0.72030514]\n",
      " [ 1.29392461]\n",
      " [ 0.82798452]\n",
      " [ 0.82798452]\n",
      " [ 0.82798452]\n",
      " [ 0.66895971]\n",
      " [-0.09534024]\n",
      " [ 0.72030514]\n",
      " [-1.29392461]\n",
      " [ 0.82798452]\n",
      " [-0.37059985]\n",
      " [-0.66895971]\n",
      " [ 0.82798452]\n",
      " [ 0.72030514]\n",
      " [ 0.82798452]\n",
      " [ 0.25436505]]\n",
      "[[ 1.02602298]\n",
      " [ 1.02602298]\n",
      " [ 0.56863831]\n",
      " [-0.47092125]\n",
      " [ 0.62994605]\n",
      " [ 0.91834361]\n",
      " [-0.17256139]\n",
      " [ 0.62994605]\n",
      " [ 1.02602298]\n",
      " [-0.17256139]\n",
      " [-0.17256139]\n",
      " [-0.00498115]\n",
      " [-0.47092125]\n",
      " [ 0.05632659]\n",
      " [ 0.45240351]\n",
      " [ 0.45240351]\n",
      " [ 1.02602298]\n",
      " [-0.47092125]\n",
      " [-0.47092125]\n",
      " [-0.62994605]\n",
      " [-0.47092125]\n",
      " [ 1.02602298]\n",
      " [-0.47092125]\n",
      " [-1.09588615]\n",
      " [ 1.49196307]\n",
      " [ 1.02602298]\n",
      " [ 1.49196307]\n",
      " [ 0.45240351]\n",
      " [ 1.02602298]\n",
      " [ 0.45240351]\n",
      " [ 1.02602298]\n",
      " [-0.17256139]\n",
      " [-0.47092125]\n",
      " [ 0.05632659]\n",
      " [ 0.05632659]\n",
      " [ 1.02602298]\n",
      " [ 1.02602298]\n",
      " [ 1.02602298]\n",
      " [ 1.02602298]\n",
      " [ 0.91834361]\n",
      " [ 1.02602298]\n",
      " [ 1.02602298]\n",
      " [ 1.02602298]\n",
      " [-0.17256139]\n",
      " [-0.56863831]\n",
      " [ 0.45240351]\n",
      " [-0.47092125]\n",
      " [ 1.02602298]\n",
      " [ 0.56863831]\n",
      " [ 0.2933787 ]\n",
      " [-0.17256139]\n",
      " [ 0.91834361]\n",
      " [ 1.49196307]\n",
      " [ 1.02602298]\n",
      " [ 0.62994605]\n",
      " [ 1.02602298]\n",
      " [ 0.86699817]\n",
      " [ 0.10269822]\n",
      " [ 0.91834361]\n",
      " [-1.09588615]\n",
      " [ 1.02602298]\n",
      " [-0.17256139]\n",
      " [-0.47092125]\n",
      " [ 1.02602298]\n",
      " [ 0.91834361]\n",
      " [ 1.02602298]\n",
      " [ 0.45240351]]\n",
      "[[ 1.21450185]\n",
      " [ 1.21450185]\n",
      " [ 0.75711718]\n",
      " [-0.65940012]\n",
      " [ 0.44146718]\n",
      " [ 0.72986473]\n",
      " [-0.36104026]\n",
      " [ 0.81842493]\n",
      " [ 0.8375441 ]\n",
      " [-0.36104026]\n",
      " [-0.36104026]\n",
      " [ 0.18349772]\n",
      " [-0.65940012]\n",
      " [ 0.24480546]\n",
      " [ 0.64088239]\n",
      " [ 0.64088239]\n",
      " [ 0.8375441 ]\n",
      " [-0.28244237]\n",
      " [-0.65940012]\n",
      " [-0.44146718]\n",
      " [-0.65940012]\n",
      " [ 0.8375441 ]\n",
      " [-0.65940012]\n",
      " [-1.28436502]\n",
      " [ 1.68044194]\n",
      " [ 1.21450185]\n",
      " [ 1.68044194]\n",
      " [ 0.64088239]\n",
      " [ 1.21450185]\n",
      " [ 0.64088239]\n",
      " [ 1.21450185]\n",
      " [-0.36104026]\n",
      " [-0.28244237]\n",
      " [ 0.24480546]\n",
      " [-0.13215228]\n",
      " [ 0.8375441 ]\n",
      " [ 1.21450185]\n",
      " [ 1.21450185]\n",
      " [ 1.21450185]\n",
      " [ 0.72986473]\n",
      " [ 0.8375441 ]\n",
      " [ 1.21450185]\n",
      " [ 1.21450185]\n",
      " [-0.36104026]\n",
      " [-0.38015944]\n",
      " [ 0.26392464]\n",
      " [-0.65940012]\n",
      " [ 0.8375441 ]\n",
      " [ 0.38015944]\n",
      " [ 0.10489983]\n",
      " [-0.36104026]\n",
      " [ 1.10682248]\n",
      " [ 1.68044194]\n",
      " [ 1.21450185]\n",
      " [ 0.81842493]\n",
      " [ 0.8375441 ]\n",
      " [ 0.6785193 ]\n",
      " [-0.08578066]\n",
      " [ 1.10682248]\n",
      " [-0.90740727]\n",
      " [ 0.8375441 ]\n",
      " [-0.36104026]\n",
      " [-0.28244237]\n",
      " [ 1.21450185]\n",
      " [ 1.10682248]\n",
      " [ 0.8375441 ]\n",
      " [ 0.26392464]]\n",
      "[[ 1.36677554]\n",
      " [ 1.06222816]\n",
      " [ 0.60484349]\n",
      " [-0.81167381]\n",
      " [ 0.28919349]\n",
      " [ 0.88213842]\n",
      " [-0.20876657]\n",
      " [ 0.97069862]\n",
      " [ 0.98981779]\n",
      " [-0.51331395]\n",
      " [-0.20876657]\n",
      " [ 0.03122403]\n",
      " [-0.50712643]\n",
      " [ 0.39707915]\n",
      " [ 0.79315608]\n",
      " [ 0.79315608]\n",
      " [ 0.68527041]\n",
      " [-0.43471606]\n",
      " [-0.81167381]\n",
      " [-0.59374087]\n",
      " [-0.50712643]\n",
      " [ 0.98981779]\n",
      " [-0.50712643]\n",
      " [-1.43663871]\n",
      " [ 1.52816825]\n",
      " [ 1.06222816]\n",
      " [ 1.83271563]\n",
      " [ 0.4886087 ]\n",
      " [ 1.06222816]\n",
      " [ 0.4886087 ]\n",
      " [ 1.36677554]\n",
      " [-0.20876657]\n",
      " [-0.43471606]\n",
      " [ 0.09253177]\n",
      " [-0.28442597]\n",
      " [ 0.68527041]\n",
      " [ 1.06222816]\n",
      " [ 1.06222816]\n",
      " [ 1.06222816]\n",
      " [ 0.88213842]\n",
      " [ 0.98981779]\n",
      " [ 1.36677554]\n",
      " [ 1.06222816]\n",
      " [-0.51331395]\n",
      " [-0.53243313]\n",
      " [ 0.11165095]\n",
      " [-0.50712643]\n",
      " [ 0.68527041]\n",
      " [ 0.22788575]\n",
      " [-0.04737386]\n",
      " [-0.51331395]\n",
      " [ 0.95454879]\n",
      " [ 1.52816825]\n",
      " [ 1.06222816]\n",
      " [ 0.66615124]\n",
      " [ 0.98981779]\n",
      " [ 0.52624561]\n",
      " [-0.23805435]\n",
      " [ 1.25909617]\n",
      " [-1.05968096]\n",
      " [ 0.98981779]\n",
      " [-0.51331395]\n",
      " [-0.43471606]\n",
      " [ 1.06222816]\n",
      " [ 0.95454879]\n",
      " [ 0.68527041]\n",
      " [ 0.11165095]]\n",
      "[[ 1.21166683]\n",
      " [ 1.21733687]\n",
      " [ 0.44973479]\n",
      " [-0.96678252]\n",
      " [ 0.13408478]\n",
      " [ 1.03724713]\n",
      " [-0.36387528]\n",
      " [ 0.81558991]\n",
      " [ 0.83470909]\n",
      " [-0.66842266]\n",
      " [-0.36387528]\n",
      " [-0.12388468]\n",
      " [-0.66223514]\n",
      " [ 0.24197045]\n",
      " [ 0.63804737]\n",
      " [ 0.94826478]\n",
      " [ 0.84037912]\n",
      " [-0.58982477]\n",
      " [-0.96678252]\n",
      " [-0.74884958]\n",
      " [-0.66223514]\n",
      " [ 0.83470909]\n",
      " [-0.66223514]\n",
      " [-1.59174742]\n",
      " [ 1.68327696]\n",
      " [ 0.90711945]\n",
      " [ 1.67760692]\n",
      " [ 0.33349999]\n",
      " [ 1.21733687]\n",
      " [ 0.6437174 ]\n",
      " [ 1.52188425]\n",
      " [-0.36387528]\n",
      " [-0.58982477]\n",
      " [-0.06257693]\n",
      " [-0.43953468]\n",
      " [ 0.84037912]\n",
      " [ 1.21733687]\n",
      " [ 1.21733687]\n",
      " [ 0.90711945]\n",
      " [ 0.72702971]\n",
      " [ 0.83470909]\n",
      " [ 1.21166683]\n",
      " [ 0.90711945]\n",
      " [-0.66842266]\n",
      " [-0.68754184]\n",
      " [-0.04345776]\n",
      " [-0.66223514]\n",
      " [ 0.84037912]\n",
      " [ 0.38299446]\n",
      " [-0.20248257]\n",
      " [-0.66842266]\n",
      " [ 0.79944008]\n",
      " [ 1.37305954]\n",
      " [ 1.21733687]\n",
      " [ 0.82125995]\n",
      " [ 1.1449265 ]\n",
      " [ 0.68135431]\n",
      " [-0.39316305]\n",
      " [ 1.10398746]\n",
      " [-1.21478967]\n",
      " [ 1.1449265 ]\n",
      " [-0.66842266]\n",
      " [-0.58982477]\n",
      " [ 1.21733687]\n",
      " [ 0.79944008]\n",
      " [ 0.53016171]\n",
      " [ 0.26675966]]\n",
      "[[ 1.07630486]\n",
      " [ 1.0819749 ]\n",
      " [ 0.31437281]\n",
      " [-0.83142054]\n",
      " [ 0.26944676]\n",
      " [ 1.1726091 ]\n",
      " [-0.22851331]\n",
      " [ 0.95095188]\n",
      " [ 0.97007106]\n",
      " [-0.53306069]\n",
      " [-0.22851331]\n",
      " [-0.25924665]\n",
      " [-0.52687316]\n",
      " [ 0.37733242]\n",
      " [ 0.77340934]\n",
      " [ 1.08362676]\n",
      " [ 0.9757411 ]\n",
      " [-0.4544628 ]\n",
      " [-0.83142054]\n",
      " [-0.88421155]\n",
      " [-0.52687316]\n",
      " [ 0.97007106]\n",
      " [-0.52687316]\n",
      " [-1.45638544]\n",
      " [ 1.81863893]\n",
      " [ 1.04248143]\n",
      " [ 1.8129689 ]\n",
      " [ 0.46886196]\n",
      " [ 1.35269884]\n",
      " [ 0.50835543]\n",
      " [ 1.65724622]\n",
      " [-0.22851331]\n",
      " [-0.4544628 ]\n",
      " [-0.19793891]\n",
      " [-0.30417271]\n",
      " [ 0.9757411 ]\n",
      " [ 1.35269884]\n",
      " [ 1.35269884]\n",
      " [ 1.04248143]\n",
      " [ 0.86239169]\n",
      " [ 0.97007106]\n",
      " [ 1.34702881]\n",
      " [ 1.04248143]\n",
      " [-0.53306069]\n",
      " [-0.55217986]\n",
      " [ 0.09190421]\n",
      " [-0.52687316]\n",
      " [ 0.9757411 ]\n",
      " [ 0.51835643]\n",
      " [-0.06712059]\n",
      " [-0.53306069]\n",
      " [ 0.93480205]\n",
      " [ 1.50842152]\n",
      " [ 1.35269884]\n",
      " [ 0.68589797]\n",
      " [ 1.28028848]\n",
      " [ 0.81671629]\n",
      " [-0.25780108]\n",
      " [ 1.23934943]\n",
      " [-1.0794277 ]\n",
      " [ 1.28028848]\n",
      " [-0.53306069]\n",
      " [-0.4544628 ]\n",
      " [ 1.35269884]\n",
      " [ 0.93480205]\n",
      " [ 0.66552368]\n",
      " [ 0.40212163]]\n",
      "[[ 0.95108899]\n",
      " [ 1.20719077]\n",
      " [ 0.18915694]\n",
      " [-0.95663642]\n",
      " [ 0.14423088]\n",
      " [ 1.29782498]\n",
      " [-0.10329743]\n",
      " [ 0.82573601]\n",
      " [ 1.09528693]\n",
      " [-0.65827656]\n",
      " [-0.35372918]\n",
      " [-0.38446252]\n",
      " [-0.40165729]\n",
      " [ 0.50254829]\n",
      " [ 0.64819347]\n",
      " [ 1.20884263]\n",
      " [ 0.85052522]\n",
      " [-0.57967867]\n",
      " [-0.70620467]\n",
      " [-0.75899568]\n",
      " [-0.65208904]\n",
      " [ 1.09528693]\n",
      " [-0.40165729]\n",
      " [-1.33116957]\n",
      " [ 1.69342306]\n",
      " [ 1.1676973 ]\n",
      " [ 1.68775303]\n",
      " [ 0.34364609]\n",
      " [ 1.22748297]\n",
      " [ 0.38313956]\n",
      " [ 1.53203035]\n",
      " [-0.35372918]\n",
      " [-0.57967867]\n",
      " [-0.32315478]\n",
      " [-0.17895684]\n",
      " [ 0.85052522]\n",
      " [ 1.22748297]\n",
      " [ 1.22748297]\n",
      " [ 0.91726555]\n",
      " [ 0.98760756]\n",
      " [ 0.84485519]\n",
      " [ 1.47224468]\n",
      " [ 0.91726555]\n",
      " [-0.65827656]\n",
      " [-0.67739574]\n",
      " [ 0.21712009]\n",
      " [-0.40165729]\n",
      " [ 0.85052522]\n",
      " [ 0.39314056]\n",
      " [ 0.05809528]\n",
      " [-0.40784481]\n",
      " [ 0.80958618]\n",
      " [ 1.63363739]\n",
      " [ 1.22748297]\n",
      " [ 0.81111385]\n",
      " [ 1.1550726 ]\n",
      " [ 0.69150041]\n",
      " [-0.38301695]\n",
      " [ 1.11413356]\n",
      " [-1.20464357]\n",
      " [ 1.1550726 ]\n",
      " [-0.40784481]\n",
      " [-0.32924692]\n",
      " [ 1.47791472]\n",
      " [ 0.80958618]\n",
      " [ 0.54030781]\n",
      " [ 0.5273375 ]]\n"
     ]
    }
   ],
   "source": [
    "prediction10 = ada_classify(test_arr, classifier_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err_arr = mat(ones((67,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_arr[prediction10!=mat(test_label_arr).T].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.7 非均衡分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7.1 其他分类性能度量指标：正确率、召回率及ROC曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Precision} = \\frac{\\text{TP}}{\\text{TP}+\\text{FP}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Recall}=\\frac{\\text{TP}}{\\text{TP}+\\text{FN}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**程序清单7-5** ROC曲线的绘制及AUC计算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_ROC(pred_strengths, class_labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    cur = (1.0, 1.0)\n",
    "    y_sum = 0.0\n",
    "    num_pos_class = sum(array(class_labels)==1.0)\n",
    "    y_step = 1/float(num_pos_class)\n",
    "    x_step = 1/float(len(class_labels)-num_pos_class)\n",
    "    sorted_indices = pred_strengths.argsort()\n",
    "    fig = plt.figure()\n",
    "    fig.clf()\n",
    "    ax = plt.subplot(111)\n",
    "    for index in sorted_indices.tolist()[0]:\n",
    "        if class_labels[index] == 1.0:\n",
    "            del_x = 0\n",
    "            del_y = y_step\n",
    "        else:\n",
    "            del_x = x_step\n",
    "            del_y = 0\n",
    "            y_sum += cur[1]\n",
    "        ax.plot([cur[0],cur[0]-del_x],[cur[1],cur[1]-del_y],c='b')\n",
    "        cur = (cur[0]-del_x, cur[1]-del_y)\n",
    "    ax.plot([0,1], [0,1], 'b--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve for AdaBoost Horse Colic Detection System')\n",
    "    ax.axis([0,1,0,1])\n",
    "    plt.show()\n",
    "    print('The Area Under the Curve is:', y_sum * x_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ada_boost_train_DS(data_arr, class_labels, num_it = 40):\n",
    "    weak_class_arr = []\n",
    "    m = shape(data_arr)[0]\n",
    "    D = mat(ones((m,1))/m)\n",
    "    agg_class_est = mat(zeros((m,1)))\n",
    "    for i in range(num_it):\n",
    "        best_stump, error, class_est = build_stump(data_arr, class_labels, D)\n",
    "        # print('D:', D.T)\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))\n",
    "        best_stump['alpha'] = alpha\n",
    "        weak_class_arr.append(best_stump)\n",
    "        # print('class_est:', class_est.T)\n",
    "        expon = multiply(-1*alpha*mat(class_labels).T, class_est)\n",
    "        D = multiply(D, exp(expon))\n",
    "        D = D/D.sum()\n",
    "        agg_class_est += alpha * class_est\n",
    "        # print('agg_class_est:', agg_class_est.T)\n",
    "        agg_errors = multiply(sign(agg_class_est)!=mat(class_labels).T, ones((m,1)))\n",
    "        error_rate = agg_errors.sum()/m\n",
    "        print('total error:', error_rate)\n",
    "        if error_rate == 0.0:\n",
    "            break\n",
    "    return weak_class_arr, agg_class_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_arr, label_arr = load_data_set('horseColicTraining2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 0.284280936455\n",
      "total error: 0.284280936455\n",
      "total error: 0.247491638796\n",
      "total error: 0.247491638796\n",
      "total error: 0.254180602007\n",
      "total error: 0.240802675585\n",
      "total error: 0.240802675585\n",
      "total error: 0.220735785953\n",
      "total error: 0.247491638796\n",
      "total error: 0.230769230769\n"
     ]
    }
   ],
   "source": [
    "classifier_array, agg_class_est = ada_boost_train_DS(dat_arr, label_arr, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102afac5048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Area Under the Curve is: 0.8582969635063604\n"
     ]
    }
   ],
   "source": [
    "plot_ROC(agg_class_est.T, label_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7.2 基于代价函数的分类器决策控制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7.3 处理非均衡问题的数据抽样方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.8 本章小结"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
